{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine\n",
    "\n",
    "Assume that we have a linearly-separable set of datapoints with classes -1 or 1.\n",
    "\n",
    "### Linear SVM with *hard* margin\n",
    "We want to separate the data (linearly) with a hyperplane $w^T + b =0$.\n",
    "*street* (i.e. two parallel planes instead of just one hyperplane $w^T x + b = 0$ with no datapoints in between the two parallel hyperplanes). So, we want\n",
    "$$\n",
    "y_i = \n",
    "\\begin{cases}\n",
    "-1  & \\text{ if } w^T x_i + b < -1 \\\\\n",
    "1  &\\text{ if } w^T x_i + b \\ge 1 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "2. The difference between the parallel hyperplanes $w^Tx + b = -1$ and $w^Tx + b = 1$ given by $\\frac{2}{||w||}$ is maximized.\n",
    "\n",
    "Combining both, the constrained minimization problem is to find\n",
    "$$\n",
    "\\underset{w, b}{\\text{minimize }}  \\frac{1}{2} w^Tw  \\text{, subject to }   \\\\\n",
    "y_i (w^T x_i + b) \\ge 1 \\text{ for all } i = 1, ..., m\n",
    "$$\n",
    "\n",
    "### Linear SVM with *soft* margin\n",
    "\n",
    "For **soft margin**, we allow datapoints to be on the street by letting the difference between the hyperplanes smaller. So we introduce a *slack* variable associated with each datapoint. \n",
    "\n",
    "The constrained minimization problem is\n",
    "$$\n",
    "\\underset{w, b, \\zeta}{\\text{minimize }} \\frac{1}{2} w^Tw + C \\sum_{i=1}^m \\zeta_i, \\text{subject to }\\\\\n",
    "y_i (w^Tx_i + b) \\ge 1 - \\zeta_i\\\\\n",
    "\\zeta_i \\ge 0 \\text{ for all } i = 1,2, ..., m\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving\n",
    "Both of the above are constrained quadratic optimization problems that can be solved using *quadratic programming*. \n",
    "\n",
    "However, we can look at the *dual* problem instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemeting Linear SVM \n",
    "\n",
    "* Very sensitive to scaling, so scaling is necessary\n",
    "* Lower `C` (strictness) value means the gap between the classes is bigger and more exceptions are allowed. \n",
    "* SVM outputs the class, not the probability of the data belonging to a certain class (like Logistic Regression classifier)\n",
    "* Good for medium and small datasets, unless using Stochastic method with `alpha = 1/(m*C)` (?)\n",
    "* For better performance, set `dual=false` (why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "# working with only petal length and petal width\n",
    "X = iris['data'][:, (2,3)]\n",
    "# Only the flower type 2\n",
    "y = (iris['target'] == 2).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = Pipeline((\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1, loss='hinge')),\n",
    "))\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means, the flower with petal length 5.5 and petal width 1.7 is indeed of flower type 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use SVM for large datasets, use `loss=hinge, alpha = 1/ (m*C)` options to apply Stochastic Gradient Descent methd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlienar SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('poly_features', PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_svm_clf = Pipeline((\n",
    "    ('poly_features', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=10, loss='hinge')),\n",
    "))\n",
    "polynomial_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
